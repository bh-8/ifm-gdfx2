\documentclass{article}

\usepackage[german]{babel}
\usepackage{csquotes}
\usepackage{geometry}
\usepackage{hyperref}

\title{Generalizable Deepfake Detection}
\author{Bernhard Birnbaum}

\begin{document}
    \maketitle

    \section{Motivation \& Stand der Technik}
    Im Rahmen des Praktikums \enquote{Implementierung in Forensik und Mediensicherheit} soll ein Framework zur Detektion von Deepfakes (Bildsequenzen) implementiert werden.
    Dabei wird neben der Detektion eine Klassifikation verschiedener Deepfake-Techniken, insbesondere \enquote{Face-Swap} und \enquote{Face-Reenactment}, etabliert.
    Im Zentrum des Projekts steht die Fragestellung, inwiefern ein geeignetes Machine-Learning-Modell~\footnote{Machine Learning, Google for Developers, \url{https://developers.google.com/machine-learning}} konzeptioniert, implementiert bzw. optimiert werden kann, das diesen Ansprüchen genügt.
    Dazu wird zunächst ein Baseline-Modell erzeugt, welches im späteren Verlauf der Untersuchung mit experimentellen Komponenten angepasst werden kann.
    Abschließend werden die Auswirkungen auf die Modell-Performance anhand geeigneter Metriken evaluiert.
    \\
    Zur Implementierung der Deepfake-Klassifikation sollen Deeplearning-Methoden~\cite{deeplearningbook} eingesetzt werden.
    \subsection{Merkmalsextraktoren: ResNet50 \& EfficientNet}
    \begin{itemize}
        \item CNNs
        \item Merkmalsextraktoren % https://medium.com/@nitishkundu1993/exploring-resnet50-an-in-depth-look-at-the-model-architecture-and-code-implementation-d8d8fa67e46f
    \end{itemize}
    \subsection{BiLSTMs}
    \begin{itemize}
        \item RNNs
        \item LSTMs
        \item BiLSTMs % https://medium.com/@anishnama20/understanding-bidirectional-lstm-for-sequential-data-processing-b83d6283befc
    \end{itemize}
    \subsection{DF40-Datenset}
    \begin{itemize}
        \item Quelle~\cite{yan2024df40}
        \item Ordnerstruktur der Daten
    \end{itemize}

    \newpage
    \section{Konzept}
    \subsection{Vorverarbeitung des Datensets}
    \begin{itemize}
        \item Preprocessing/Normalisierung/Mischen
        \item Anzahl Elemente Training/Test pro Klasse/Splits
    \end{itemize}
    \subsection{Modelle}
    Aufbau und Funktion der einzelnen Schichten:
    \begin{itemize}
        \item Input-Layer
        \item Resnet50-Layer
        \item GlovalAvgPooling-Layer
        \item BiLSTM/Layer
        \item DropOut-Layer
        \item Dense-Layer (Softmax, L2-Regularisierung, Kernel/Bias)
    \end{itemize}
    \subsection{Training}
    \begin{itemize}
        \item Optimizer (adam)
        \item Minimierung Loss Funktion (categorical crossentropy)
        \item LR-Scheduler (ReduceLROnPlateau)
        \item Epochen/Early-Stopping
    \end{itemize}
    \subsection{Validation}
    \begin{itemize}
        \item categorical accuracy
        \item f1 score
        \item area under curve
        \item Detektionszeit
    \end{itemize}

    \newpage
    \section{Implementierung}
    \begin{itemize}
        \item Entwicklungsumgebung/Cluster: MiniForge
        \item Python- und Tool-Versionen, Bibliotheken, ... % https://www.tensorflow.org/guide/keras/training_with_built_in_methods
    \end{itemize}
    \subsection{PyTorch vs. Tensorflow}
    \begin{itemize}
        \item Vergleich und Abwägung
    \end{itemize}
    \section{Evaluation}
    \begin{itemize}
        \item Model Performance anhand von Metriken
    \end{itemize}

    \section{Zusammenfassung}
    \subsection{Fazit}
    \subsection{Ausblick für zukünftige Arbeiten}
    \begin{itemize}
        \item zusätzlicher Validierungsdatensatz % https://huggingface.co/datasets/faridlab/deepspeak_v1
        \item Weitere Klassen einfügen (über FS und FR hinaus)
        \item Weitere Optimierungsmöglichkeiten
    \end{itemize}

    \bibliographystyle{plain}
    \bibliography{refs}

    \section*{Anhang}
    \begin{itemize}
        \item Quellcodeauszüge
        \item umgesetzt:
        \item Normalisierung gefixed (Resnet/EfficientNet)
        \item LR-Scheduler raus (bereits durch Adam abgedeckt), manuelle Anpassung der Lernrate/weight freezing
    \end{itemize}
    \begin{itemize}
        \item Weitere Frage: Regularisierung sinnvoll? Bias/Kernel
    \end{itemize}
\end{document}
