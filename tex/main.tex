\documentclass{article}

\usepackage[german]{babel}
\usepackage{csquotes}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{scrextend}
\usepackage{xurl}
\deffootnote{0em}{1.6em}{\thefootnotemark.\enskip}

\title{Generalizable Deepfake Detection}
\author{Bernhard Birnbaum}

\begin{document}
    \maketitle

    \section{Motivation \& Stand der Technik}
    Im Rahmen des Praktikums \enquote{Implementierung in Forensik und Mediensicherheit} soll ein Framework zur Detektion von Deepfakes (Bildsequenzen) implementiert werden.
    Dabei wird neben der Detektion eine Klassifikation verschiedener Deepfake-Techniken, insbesondere \enquote{Face-Swap} und \enquote{Face-Reenactment}, etabliert.
    Im Zentrum des Projekts steht die Fragestellung, inwiefern ein geeignetes Machine-Learning-Modell~\footnote{Machine Learning, Google for Developers, \url{https://developers.google.com/machine-learning}} konzeptioniert, implementiert bzw. optimiert werden kann, das diesen Ansprüchen genügt.
    Dazu wird zunächst ein Baseline-Modell trainiert, welches im weiteren Verlauf der Untersuchung mit verschiedenen Komponenten angepasst werden kann.
    Abschließend sollen die Auswirkungen auf die Modell-Performance anhand geeigneter Metriken evaluiert werden.
    Zur Implementierung der Deepfake-Klassifikation werden Deeplearning-Methoden~\cite{deeplearningbook} eingesetzt.
    \subsection{Merkmalsextraktoren als Baseline-Modelle}
    \subsubsection{ResNet50}
    ResNet50 ist eine CNN-Architektur (\enquote{Convolutional Neural Networks}) für tiefe neuronale Netzwerke, die zu den \enquote{Residual Networks}~\cite{resnet} gehört und eine Tiefe von 50 Schichten aufweist.
    ResNet-Modelle sind besonders gut für die Klassifikation von Bildern geeignet und erzielen dabei State-of-the-Art-Ergebnisse, weshalb sie auch häufig als Merkmalsextraktoren im Bereich des maschinellen Sehens eingesetzt werden~\footnote{Exploring ResNet50: An In-Depth Look at the Model Architecture and Code Implementation, \url{https://medium.com/@nitishkundu1993/exploring-resnet50-an-in-depth-look-at-the-model-architecture-and-code-implementation-d8d8fa67e46f}}.
    Um das Problem der Vanishing-Gradients zu lösen, also dass die Gradienten in den tieferen Schichten verschwindend gering werden, nutzt ResNet sogenannte \enquote{Residual Connections}, wodurch die Eingabedaten eine oder mehrere Schichten im Netzwerk \enquote{überspringen} können.
    \subsubsection{EfficientNetB0}
    EfficientNetB0 ist neben ResNet50 eine alternative CNN-Architektur und gehört zur EfficientNet-Familie~\cite{efficientnet}.
    Der Hauptunterschied zu ResNet besteht in der Skalierung: bei EfficientNet können nicht nur weitere Schichten hinzugefügt, sondern das Netz kann in Tiefe, Breite und Auflösung angepasst werden (\enquote{Compound Model Scaling})~\footnote{Understanding EfficientNet - The most powerful CNN architecture, \url{https://arjun-sarkar786.medium.com/understanding-efficientnet-the-most-powerful-cnn-architecture-eaeb40386fad}}.
    Desweiteren nutzt EfficientNet sogenannte \enquote{MBConv-Blöcke}, eine effizientere Strategie zur Implementierung von \enquote{Inverted Residual Blocks}.
    Dadurch verringert sich die Parameteranzahl im Vergleich zu ResNet erheblich, was zu einem deutlich reduzierten Rechenaufwand bei ählicher Genauigkeit führt.
    \subsection{BiLSTMs}
    \begin{itemize}
        \item RNNs
        \item LSTMs
        \item BiLSTMs % https://medium.com/@anishnama20/understanding-bidirectional-lstm-for-sequential-data-processing-b83d6283befc
    \end{itemize}
    \subsection{DF40-Datenset}
    Um einen Klassifikator zu trainieren, der neben der Detektion zusätzlich verschiedene Arten von Deepfakes erkennen soll, ist ein breit gestreuter Trainings- bzw. Validierungsdatensatz notwendig.
    Dafür wurde das DF40-Datenset~\cite{yan2024df40} ausgewählt, eine Sammlung von Deepfake-Erzeugnissen von 40 verschiedenen Tools inklusive der Originaldaten.
    Im Rahmen dieser Arbeit soll in einem ersten Proof-of-Concept zunächst zwischen den Klassen \enquote{original}, \enquote{faceswap} (10 Tools) und \enquote{facereenactment} (13 Tools) unterschieden werden.

    \begin{itemize}
        \item Quelle
        \item Ordnerstruktur der Daten
    \end{itemize}

    \newpage
    \section{Konzept}
    \subsection{Vorverarbeitung des Datensets}
    \begin{itemize}
        \item Preprocessing/Normalisierung/Mischen
        \item Anzahl Elemente Training/Test pro Klasse/Splits
    \end{itemize}
    \subsection{Modelle}
    Aufbau und Funktion der einzelnen Schichten:
    \begin{itemize}
        \item Input-Layer
        \item Resnet50-Layer
        \item GlovalAvgPooling-Layer
        \item BiLSTM/Layer
        \item DropOut-Layer
        \item Dense-Layer (Softmax, L2-Regularisierung, Kernel/Bias)
    \end{itemize}
    \subsection{Training}
    \begin{itemize}
        \item Optimizer (adam)
        \item Minimierung Loss Funktion (categorical crossentropy)
        \item LR-Scheduler (ReduceLROnPlateau)
        \item Epochen/Early-Stopping
    \end{itemize}
    \subsection{Validation}
    \begin{itemize}
        \item categorical accuracy
        \item f1 score
        \item area under curve
        \item Detektionszeit
    \end{itemize}

    \newpage
    \section{Implementierung}
    \begin{itemize}
        \item Entwicklungsumgebung/Cluster: MiniForge
        \item Python- und Tool-Versionen, Bibliotheken, ... % https://www.tensorflow.org/guide/keras/training_with_built_in_methods
    \end{itemize}
    \subsection{PyTorch vs. Tensorflow}
    \begin{itemize}
        \item Vergleich und Abwägung
    \end{itemize}
    \section{Evaluation}
    \begin{itemize}
        \item Model Performance anhand von Metriken
    \end{itemize}

    \section{Zusammenfassung}
    \subsection{Fazit}
    \subsection{Ausblick für zukünftige Arbeiten}
    \begin{itemize}
        \item zusätzlicher Validierungsdatensatz % https://huggingface.co/datasets/faridlab/deepspeak_v1
        \item Weitere Klassen einfügen (über FS und FR hinaus)
        \item Weitere Optimierungsmöglichkeiten
        \item ViT
        \item Vorverarbeitungsmethoden (Frames aus Video extrahieren und FaceCropping)
        \item Auflösung erhöhen: Merkmalsextraktoren, Input-Size, ...
    \end{itemize}

    \bibliographystyle{plain}
    \bibliography{refs}

    \section*{Anhang}
    \begin{itemize}
        \item Quellcodeauszüge
        \item umgesetzt:
        \item Normalisierung gefixed (Resnet/EfficientNet)
        \item LR-Scheduler raus (bereits durch Adam abgedeckt), manuelle Anpassung der Lernrate/weight freezing
        \item class weights eingebaut: nachteile von over/undersampling
        \item Generell bericht: Was hat gut funktioniert, was nicht?
    \end{itemize}
\end{document}
